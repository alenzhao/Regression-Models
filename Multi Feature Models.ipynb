{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from itertools import *\n",
    "import math\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    \"\"\"\n",
    "        Args : \n",
    "                dataset is a string mentioning the dataset location and name\n",
    "                    -- assumes the format is .dat\n",
    "        Output : Returns 2 numpy arrays\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(dataset+\".dat\")\n",
    "    X = data[:,:-1]\n",
    "    Y = data[:,-1]\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combinations(n_features, degree):\n",
    "    return chain.from_iterable(combinations_with_replacement(range(n_features), i) for i in range(degree + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_z(X, degree):\n",
    "    Z = []\n",
    "    for x in X:\n",
    "        temp1 = []\n",
    "        for item in combinations(X.shape[1],degree):\n",
    "            temp2 = [1]\n",
    "            for i in item:\n",
    "                temp2.append(x[i])\n",
    "            \n",
    "            product = 1\n",
    "            for i in temp2:\n",
    "                product = product * i\n",
    "            temp1.append(product)\n",
    "        Z.append(temp1)\n",
    "    \n",
    "    return np.array(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_feature_linear_regression(X,Y,degree):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "                X : data matrix\n",
    "                Y : y value matrix of input\n",
    "    \"\"\"\n",
    "    Z = construct_z(X,degree)\n",
    "    Z_T = np.transpose(Z.copy())\n",
    "    theta = dot(dot(inv(dot(Z_T,Z)),Z_T),Y)\n",
    "    return theta,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_mse(predict_Y,Y):\n",
    "    m = len(predict_Y)\n",
    "    error = 0.\n",
    "    for idx in range(m):\n",
    "        error = error + ((predict_Y[idx]- Y[idx])**2)\n",
    "    return error/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def do_multi_feature_linear_regression_experiment(dataset,degree = 2,n_folds=10,verbose = True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            dataset is a string mentioning the dataset location and name\n",
    "                -- assumes the format is .dat\n",
    "            degree : it denotes the degree of polynomial for constructing Z\n",
    "    \"\"\"\n",
    "    X,Y = load_data(\"data/\"+dataset)\n",
    "    cv = cross_validation.KFold(len(Y),n_folds,shuffle=True,random_state=5)\n",
    "    avg_test_error = []\n",
    "    avg_train_error = []\n",
    "    \n",
    "    fold = 0\n",
    "    for train_ind, test_ind in cv:\n",
    "        fold= fold + 1\n",
    "        theta,Z = multi_feature_linear_regression(X[train_ind],Y[train_ind],degree)\n",
    "        \n",
    "        #Calculating training error\n",
    "        predict_Y_train = dot(theta,np.transpose(Z))\n",
    "        train_error = calculate_mse(predict_Y_train,Y[train_ind])\n",
    "        \n",
    "        #Calculating testing error\n",
    "        \n",
    "        Z_test = construct_z(X[test_ind],degree)\n",
    "        predict_Y_test = dot(theta,np.transpose(Z_test))\n",
    "        test_error = calculate_mse(predict_Y_test,Y[test_ind])\n",
    "        \n",
    "        avg_train_error.append(train_error)\n",
    "        avg_test_error.append(test_error)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"For Fold : %d\" % fold)\n",
    "            print(\"Training error : %.4f & Testing error : %.4f\" %(train_error,test_error))\n",
    "        \n",
    "    print(\"\\nAvg Training error : %.4f & Avg Testing error : %.4f for %d folds\" \n",
    "          %(np.mean(avg_train_error),np.mean(avg_test_error),n_folds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.2549 & Testing error : 0.2900\n",
      "For Fold : 2\n",
      "Training error : 0.2572 & Testing error : 0.2680\n",
      "For Fold : 3\n",
      "Training error : 0.2582 & Testing error : 0.2607\n",
      "For Fold : 4\n",
      "Training error : 0.2629 & Testing error : 0.2174\n",
      "For Fold : 5\n",
      "Training error : 0.2558 & Testing error : 0.2815\n",
      "For Fold : 6\n",
      "Training error : 0.2573 & Testing error : 0.2676\n",
      "For Fold : 7\n",
      "Training error : 0.2559 & Testing error : 0.2804\n",
      "For Fold : 8\n",
      "Training error : 0.2577 & Testing error : 0.2634\n",
      "For Fold : 9\n",
      "Training error : 0.2608 & Testing error : 0.2362\n",
      "For Fold : 10\n",
      "Training error : 0.2610 & Testing error : 0.2339\n",
      "\n",
      "Avg Training error : 0.2582 & Avg Testing error : 0.2599 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.2582 & Avg Testing error : 0.2599 for 10 folds\n",
      "\n",
      "Avg Training error : 0.2575 & Avg Testing error : 0.2599 for 10 folds\n",
      "\n",
      "Avg Training error : 0.2563 & Avg Testing error : 0.2599 for 10 folds\n",
      "\n",
      "Avg Training error : 0.2560 & Avg Testing error : 0.2609 for 10 folds\n",
      "\n",
      "Avg Training error : 0.2500 & Avg Testing error : 0.2672 for 10 folds\n",
      "\n",
      "Avg Training error : 0.2422 & Avg Testing error : 0.2798 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\",degree=2, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\",degree=3, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\",degree=4, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\",degree=5, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\",degree=10, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\",degree=15, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.0199 & Avg Testing error : 0.0200 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set2\",degree=2, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.0103 & Avg Testing error : 0.0104 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set2\",degree=3, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.0103 & Avg Testing error : 0.0104 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set2\",degree=4, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.0047 & Avg Testing error : 0.0048 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set2\",degree=5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.0023 & Avg Testing error : 0.0026 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set2\",degree=15, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set3\",degree=2, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set3\",degree=3, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set3\",degree=4, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set3\",degree=5, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set3\",degree=10, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.2507 & Avg Testing error : 0.2508 for 10 folds\n",
      "\n",
      "Avg Training error : 0.0039 & Avg Testing error : 0.0039 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set3\",degree=2, verbose = False)\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set4\",degree=2, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative solution using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(Z,Y,max_iterations=10**8, error_threshold=0.2, learning_rate=1./(10**4)):\n",
    "    theta=np.zeros(Z.shape[1])\n",
    "    predict_Y = dot(theta,np.transpose(Z))\n",
    "    prev_error = inf\n",
    "    error = calculate_mse(predict_Y, Y)\n",
    "    iterations = 0\n",
    "    \n",
    "    while abs(error-prev_error) > error_threshold and iterations <= max_iterations:\n",
    "        random_state = np.random.get_state()\n",
    "        np.random.shuffle(Z)\n",
    "        np.random.set_state(random_state)\n",
    "        np.random.shuffle(Y)\n",
    "        \n",
    "        for idx,Z_i in enumerate(Z):\n",
    "            predict_Y = dot(np.transpose(theta),Z[idx])\n",
    "            diff =  learning_rate * dot((predict_Y - Y[idx]), Z[idx])\n",
    "            theta = theta - diff\n",
    "        \n",
    "        prev_error = error\n",
    "        predict_Y = dot(theta,np.transpose(Z))\n",
    "        error = calculate_mse(predict_Y, Y)\n",
    "        iterations = iterations + 1\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_stochastic_gradient_descent_experiment(dataset,degree = 2,n_folds=10,\n",
    "                            max_iterations=10**8, error_threshold=0.2, learning_rate=1./(10**4),verbose = True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            dataset is a string mentioning the dataset location and name\n",
    "                -- assumes the format is .dat\n",
    "            degree : it denotes the degree of polynomial for constructing Z\n",
    "    \"\"\"\n",
    "    X,Y = load_data(\"data/\"+dataset)\n",
    "    cv = cross_validation.KFold(len(Y),n_folds,shuffle=True,random_state=5)\n",
    "    avg_test_error = []\n",
    "    avg_train_error = []\n",
    "    \n",
    "    fold = 0\n",
    "    for train_ind, test_ind in cv:\n",
    "        fold= fold + 1\n",
    "        Z = construct_z(X[train_ind],degree)\n",
    "        \n",
    "        theta = stochastic_gradient_descent(Z,Y[train_ind]\n",
    "                    ,max_iterations= max_iterations,learning_rate=learning_rate,error_threshold=error_threshold)\n",
    "        \n",
    "        #Calculating training error\n",
    "        predict_Y_train = dot(theta,np.transpose(Z))\n",
    "        train_error = calculate_mse(predict_Y_train,Y[train_ind])\n",
    "        \n",
    "        #Calculating testing error\n",
    "        \n",
    "        Z_test = construct_z(X[test_ind],degree)\n",
    "        predict_Y_test = dot(theta,np.transpose(Z_test))\n",
    "        test_error = calculate_mse(predict_Y_test,Y[test_ind])\n",
    "        \n",
    "        avg_train_error.append(train_error)\n",
    "        avg_test_error.append(test_error)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"For Fold : %d\" % fold)\n",
    "            print(\"Training error : %.4f & Testing error : %.4f\" %(train_error,test_error))\n",
    "        \n",
    "    print(\"\\nAvg Training error : %.4f & Avg Testing error : %.4f for %d folds\" \n",
    "          %(np.mean(avg_train_error),np.mean(avg_test_error),n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 5.8060 & Testing error : 0.3384\n",
      "For Fold : 2\n",
      "Training error : 5.6371 & Testing error : 0.3342\n",
      "For Fold : 3\n",
      "Training error : 5.6297 & Testing error : 0.2858\n",
      "For Fold : 4\n",
      "Training error : 5.8256 & Testing error : 0.2693\n",
      "For Fold : 5\n",
      "Training error : 5.6981 & Testing error : 0.3443\n",
      "For Fold : 6\n",
      "Training error : 5.5651 & Testing error : 0.3350\n",
      "For Fold : 7\n",
      "Training error : 5.4374 & Testing error : 0.3568\n",
      "For Fold : 8\n",
      "Training error : 5.7708 & Testing error : 0.3149\n",
      "For Fold : 9\n",
      "Training error : 5.4241 & Testing error : 0.3157\n",
      "For Fold : 10\n",
      "Training error : 5.7120 & Testing error : 0.3152\n",
      "\n",
      "Avg Training error : 5.6506 & Avg Testing error : 0.3210 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_stochastic_gradient_descent_experiment(\"mvar-set1\",max_iterations=10**8, error_threshold=0.01, learning_rate=1./(10**4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.0259 & Testing error : 0.0243\n",
      "For Fold : 2\n",
      "Training error : 0.0258 & Testing error : 0.0248\n",
      "For Fold : 3\n",
      "Training error : 0.0256 & Testing error : 0.0269\n",
      "For Fold : 4\n",
      "Training error : 0.0253 & Testing error : 0.0292\n",
      "For Fold : 5\n",
      "Training error : 0.0256 & Testing error : 0.0267\n",
      "For Fold : 6\n",
      "Training error : 0.0258 & Testing error : 0.0251\n",
      "For Fold : 7\n",
      "Training error : 0.0258 & Testing error : 0.0250\n",
      "For Fold : 8\n",
      "Training error : 0.0261 & Testing error : 0.0224\n",
      "For Fold : 9\n",
      "Training error : 0.0257 & Testing error : 0.0260\n",
      "For Fold : 10\n",
      "Training error : 0.0256 & Testing error : 0.0267\n",
      "\n",
      "Avg Training error : 0.0257 & Avg Testing error : 0.0257 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_stochastic_gradient_descent_experiment(\"mvar-set2\",max_iterations=10**8, error_threshold=0.2, learning_rate=1/(10**4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 23.6304 & Testing error : 0.2461\n",
      "For Fold : 2\n",
      "Training error : 23.5979 & Testing error : 0.2542\n",
      "For Fold : 3\n",
      "Training error : 23.5338 & Testing error : 0.2518\n",
      "For Fold : 4\n",
      "Training error : 23.4210 & Testing error : 0.2517\n",
      "For Fold : 5\n",
      "Training error : 23.7166 & Testing error : 0.2500\n",
      "For Fold : 6\n",
      "Training error : 23.5130 & Testing error : 0.2473\n",
      "For Fold : 7\n",
      "Training error : 23.4939 & Testing error : 0.2501\n",
      "For Fold : 8\n",
      "Training error : 23.6354 & Testing error : 0.2490\n",
      "For Fold : 9\n",
      "Training error : 23.5993 & Testing error : 0.2526\n",
      "For Fold : 10\n",
      "Training error : 23.6554 & Testing error : 0.2561\n",
      "\n",
      "Avg Training error : 23.5797 & Avg Testing error : 0.2509 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_stochastic_gradient_descent_experiment(\"mvar-set3\",max_iterations=10**8, error_threshold=0.00001, learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 23.6674 & Testing error : 0.2462\n",
      "For Fold : 2\n",
      "Training error : 23.4412 & Testing error : 0.2541\n",
      "For Fold : 3\n",
      "Training error : 23.5466 & Testing error : 0.2520\n",
      "For Fold : 4\n",
      "Training error : 23.5924 & Testing error : 0.2517\n",
      "For Fold : 5\n",
      "Training error : 23.7727 & Testing error : 0.2503\n",
      "For Fold : 6\n",
      "Training error : 23.5661 & Testing error : 0.2473\n",
      "For Fold : 7\n",
      "Training error : 23.6186 & Testing error : 0.2502\n",
      "For Fold : 8\n",
      "Training error : 23.6649 & Testing error : 0.2490\n",
      "For Fold : 9\n",
      "Training error : 23.5918 & Testing error : 0.2527\n",
      "For Fold : 10\n",
      "Training error : 23.5811 & Testing error : 0.2561\n",
      "\n",
      "Avg Training error : 23.6043 & Avg Testing error : 0.2510 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_stochastic_gradient_descent_experiment(\"mvar-set3\",max_iterations=10**8, error_threshold=0.00001, learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.0046 & Testing error : 0.0040\n",
      "For Fold : 2\n",
      "Training error : 0.0046 & Testing error : 0.0037\n",
      "For Fold : 3\n",
      "Training error : 0.0046 & Testing error : 0.0040\n",
      "For Fold : 4\n",
      "Training error : 0.0047 & Testing error : 0.0041\n",
      "For Fold : 5\n",
      "Training error : 0.0046 & Testing error : 0.0042\n",
      "For Fold : 6\n",
      "Training error : 0.0045 & Testing error : 0.0039\n",
      "For Fold : 7\n",
      "Training error : 0.0046 & Testing error : 0.0038\n",
      "For Fold : 8\n",
      "Training error : 0.0047 & Testing error : 0.0038\n",
      "For Fold : 9\n",
      "Training error : 0.0046 & Testing error : 0.0042\n",
      "For Fold : 10\n",
      "Training error : 0.0046 & Testing error : 0.0040\n",
      "\n",
      "Avg Training error : 0.0046 & Avg Testing error : 0.0040 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_stochastic_gradient_descent_experiment(\"mvar-set4\",max_iterations=10**8, error_threshold=0.00001, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.2549 & Testing error : 0.2900\n",
      "For Fold : 2\n",
      "Training error : 0.2572 & Testing error : 0.2680\n",
      "For Fold : 3\n",
      "Training error : 0.2582 & Testing error : 0.2607\n",
      "For Fold : 4\n",
      "Training error : 0.2629 & Testing error : 0.2174\n",
      "For Fold : 5\n",
      "Training error : 0.2558 & Testing error : 0.2815\n",
      "For Fold : 6\n",
      "Training error : 0.2573 & Testing error : 0.2676\n",
      "For Fold : 7\n",
      "Training error : 0.2559 & Testing error : 0.2804\n",
      "For Fold : 8\n",
      "Training error : 0.2577 & Testing error : 0.2634\n",
      "For Fold : 9\n",
      "Training error : 0.2608 & Testing error : 0.2362\n",
      "For Fold : 10\n",
      "Training error : 0.2610 & Testing error : 0.2339\n",
      "\n",
      "Avg Training error : 0.2582 & Avg Testing error : 0.2599 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_multi_feature_linear_regression_experiment(\"mvar-set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve dual problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k(X_i, X,sigma=1):\n",
    "    \"\"\"\n",
    "    Gaussian kernel similarity function\n",
    "    \"\"\"\n",
    "    dist = np.linalg.norm(X_i - X)\n",
    "    similarity = math.exp(-0.5 * dist/ (sigma**2))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gram_matrix(X,sigma=1):\n",
    "    \"\"\"\n",
    "    Construct gram's matrix\n",
    "    \"\"\"\n",
    "    G = np.zeros((X.shape[0],X.shape[0]))\n",
    "    \n",
    "    for i in xrange(X.shape[0]):\n",
    "        for j in xrange(X.shape[0]):\n",
    "            G[i,j] = k(X[i],X[j],sigma)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel_regression(X,Y,sigma=1):\n",
    "    \"\"\"\n",
    "        Args : \n",
    "                X : training data\n",
    "                Y : prediction_value\n",
    "        Returns :\n",
    "                theta : parameters for the linear regression\n",
    "    \"\"\"\n",
    "    G = gram_matrix(X,sigma)\n",
    "    alpha = dot(inv(G),Y)\n",
    "    return alpha, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_predict_y(predict_X,X,alpha):\n",
    "    predict_y = []\n",
    "    for x in predict_X:\n",
    "        predict = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            predict = predict + (alpha[i]*k(X[i,:],x))\n",
    "        predict_y.append(predict)\n",
    "    return predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_gaussian_kernel_regression_experiment(dataset,degree = 2,n_folds=10,\n",
    "                            sigma = 1,verbose = True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            dataset is a string mentioning the dataset location and name\n",
    "                -- assumes the format is .dat\n",
    "            degree : it denotes the degree of polynomial for constructing Z\n",
    "    \"\"\"\n",
    "    X,Y = load_data(\"data/\"+dataset)\n",
    "    cv = cross_validation.KFold(len(Y),n_folds,shuffle=True,random_state=5)\n",
    "    avg_test_error = []\n",
    "    avg_train_error = []\n",
    "    \n",
    "    \n",
    "    fold = 0\n",
    "    for train_ind, test_ind in cv:\n",
    "        fold= fold + 1\n",
    "        alpha,G = gaussian_kernel_regression(X[train_ind],Y[train_ind],sigma)\n",
    "        \n",
    "        #pass sigma\n",
    "        #Calculating training error\n",
    "        predict_Y_train = calculate_predict_y(X[train_ind],X[train_ind],alpha)\n",
    "        train_error = calculate_mse(predict_Y_train,Y[train_ind])\n",
    "        \n",
    "        #Calculating testing error\n",
    "        predict_Y_test = calculate_predict_y(X[test_ind],X[train_ind],alpha)\n",
    "        test_error = calculate_mse(predict_Y_test,Y[test_ind])\n",
    "        \n",
    "        avg_train_error.append(train_error)\n",
    "        avg_test_error.append(test_error)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"For Fold : %d\" % fold)\n",
    "            print(\"Training error : %.4f & Testing error : %.4f\" %(train_error,test_error))\n",
    "        \n",
    "    print(\"\\nAvg Training error : %.4f & Avg Testing error : %.4f for %d folds\" \n",
    "          %(np.mean(avg_train_error),np.mean(avg_test_error),n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.0000 & Testing error : 0.0029\n",
      "For Fold : 2\n",
      "Training error : 0.0000 & Testing error : 0.0032\n",
      "For Fold : 3\n",
      "Training error : 0.0000 & Testing error : 0.0030\n",
      "For Fold : 4\n",
      "Training error : 0.0000 & Testing error : 0.0035\n",
      "For Fold : 5\n",
      "Training error : 0.0000 & Testing error : 0.0033\n",
      "For Fold : 6\n",
      "Training error : 0.0000 & Testing error : 0.0029\n",
      "For Fold : 7\n",
      "Training error : 0.0000 & Testing error : 0.0030\n",
      "For Fold : 8\n",
      "Training error : 0.0000 & Testing error : 0.0028\n",
      "For Fold : 9\n",
      "Training error : 0.0000 & Testing error : 0.0032\n",
      "For Fold : 10\n",
      "Training error : 0.0000 & Testing error : 0.0033\n",
      "\n",
      "Avg Training error : 0.0000 & Avg Testing error : 0.0031 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_gaussian_kernel_regression_experiment(\"mvar-set2\",sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.1786 & Testing error : 0.1536\n",
      "For Fold : 2\n",
      "Training error : 0.1722 & Testing error : 0.1523\n",
      "For Fold : 3\n",
      "Training error : 0.1744 & Testing error : 0.1807\n",
      "For Fold : 4\n",
      "Training error : 0.1727 & Testing error : 0.1842\n",
      "For Fold : 5\n",
      "Training error : 0.1757 & Testing error : 0.1778\n",
      "For Fold : 6\n",
      "Training error : 0.1744 & Testing error : 0.1420\n",
      "For Fold : 7\n",
      "Training error : 0.1720 & Testing error : 0.1739\n",
      "For Fold : 8\n",
      "Training error : 0.1752 & Testing error : 0.1448\n",
      "For Fold : 9\n",
      "Training error : 0.1750 & Testing error : 0.1583\n",
      "For Fold : 10\n",
      "Training error : 0.1703 & Testing error : 0.1870\n",
      "\n",
      "Avg Training error : 0.1741 & Avg Testing error : 0.1654 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_gaussian_kernel_regression_experiment(\"mvar-set2\",sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.0096 & Testing error : 0.0095\n",
      "For Fold : 2\n",
      "Training error : 0.0098 & Testing error : 0.0116\n",
      "For Fold : 3\n",
      "Training error : 0.0098 & Testing error : 0.0114\n",
      "For Fold : 4\n",
      "Training error : 0.0097 & Testing error : 0.0117\n",
      "For Fold : 5\n",
      "Training error : 0.0091 & Testing error : 0.0102\n",
      "For Fold : 6\n",
      "Training error : 0.0097 & Testing error : 0.0099\n",
      "For Fold : 7\n",
      "Training error : 0.0104 & Testing error : 0.0118\n",
      "For Fold : 8\n",
      "Training error : 0.0100 & Testing error : 0.0107\n",
      "For Fold : 9\n",
      "Training error : 0.0106 & Testing error : 0.0122\n",
      "For Fold : 10\n",
      "Training error : 0.0105 & Testing error : 0.0115\n",
      "\n",
      "Avg Training error : 0.0099 & Avg Testing error : 0.0110 for 10 folds\n"
     ]
    }
   ],
   "source": [
    "do_gaussian_kernel_regression_experiment(\"mvar-set2\",sigma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time comparison between primal and dual solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold : 1\n",
      "Training error : 0.0000 & Testing error : 0.0029\n",
      "For Fold : 2\n",
      "Training error : 0.0000 & Testing error : 0.0032\n",
      "For Fold : 3\n",
      "Training error : 0.0000 & Testing error : 0.0030\n",
      "For Fold : 4\n",
      "Training error : 0.0000 & Testing error : 0.0035\n",
      "For Fold : 5\n",
      "Training error : 0.0000 & Testing error : 0.0033\n",
      "For Fold : 6\n",
      "Training error : 0.0000 & Testing error : 0.0029\n",
      "For Fold : 7\n",
      "Training error : 0.0000 & Testing error : 0.0030\n",
      "For Fold : 8\n",
      "Training error : 0.0000 & Testing error : 0.0028\n",
      "For Fold : 9\n",
      "Training error : 0.0000 & Testing error : 0.0032\n",
      "For Fold : 10\n",
      "Training error : 0.0000 & Testing error : 0.0033\n",
      "\n",
      "Avg Training error : 0.0000 & Avg Testing error : 0.0031 for 10 folds\n",
      "Time taken :  608.017000198 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "do_gaussian_kernel_regression_experiment(\"mvar-set2\")\n",
    "print(\"Time taken :  %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avg Training error : 0.0199 & Avg Testing error : 0.0200 for 10 folds\n",
      "Time taken :  0.309000015259 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "do_multi_feature_linear_regression_experiment(\"mvar-set2\",degree=2, verbose = False)\n",
    "print(\"Time taken :  %s seconds\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
